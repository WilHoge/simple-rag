{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grpcio==1.60.0 | tail -n 1\n",
    "!pip install pymilvus | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql==0.4.1 | tail -n 1\n",
    "!pip install sqlalchemy==1.4.46 | tail -n 1\n",
    "!pip install sqlalchemy==1.4.46 \"pyhive[presto]\" | tail -n 1\n",
    "!pip install sentence_transformers | tail -n 1\n",
    "!pip install python-dotenv | tail -n 1\n",
    "!pip install ibm-cloud-sdk-core | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_watson_machine_learning | tail -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"0f894bac-9abe-4a26-a17c-958186743029\"\n",
    "ACCESS_TOKEN=\"p-2+l6q+zqZH5sLma42mP5oIaw==;7GofcXPpkilxSWLnqpRkIQ==:N7ooxvSB8bH0NjnAMTt9+5tTm7F6AJIFiloNFkWc0CVyTZWoyym2RFQTctDmh0frrgOAr1e7m28YnQj4/GLgcltCsXNX5vdgOA==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_cloud_sdk_core import IAMTokenManager\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv('config.env')\n",
    "\n",
    "# Connection variables\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None) \n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "\n",
    "creds = {\n",
    "    \"url\": ibm_cloud_url,\n",
    "    \"apikey\": api_key \n",
    "}\n",
    "access_token = IAMTokenManager(\n",
    "    apikey = api_key,\n",
    "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    ").get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    ")\n",
    "\n",
    "import os \n",
    "\n",
    "host = os.getenv(\"MILVUS_HOST\", None)\n",
    "port = os.getenv(\"MILVUS_PORT\", None)\n",
    "password = 'password'\n",
    "user = 'ibmlhadmin'\n",
    "server_pem_path = 'cert.crt'\n",
    "\n",
    "connections.connect(alias = 'default',\n",
    "                   host = host,\n",
    "                   port = port,\n",
    "                   user = user,\n",
    "                   password = password,\n",
    "                   server_pem_path = server_pem_path,\n",
    "                   server_name = 'watsonxdata',\n",
    "                   secure = True)\n",
    "\n",
    "# Load collection\n",
    "\n",
    "basic_collection = Collection(\"wiki_articles\")      \n",
    "basic_collection.load()\n",
    "\n",
    "# Query function\n",
    "def query_milvus(query, num_results=5):\n",
    "    \n",
    "    # Vectorize query\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n",
    "    query_embeddings = model.encode([query])\n",
    "\n",
    "    # Search\n",
    "    search_params = {\n",
    "        \"metric_type\": \"L2\", \n",
    "        \"params\": {\"nprobe\": 5}\n",
    "    }\n",
    "    results = basic_collection.search(\n",
    "        data=query_embeddings, \n",
    "        anns_field=\"vector\", \n",
    "        param=search_params,\n",
    "        limit=num_results,\n",
    "        expr=None, \n",
    "        output_fields=['article_text'],\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consider how climate change may relate to other industries and processes related to your business\n",
    "\n",
    "question_text = \"What can my company do to help fight climate change?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Milvus \n",
    "\n",
    "def get_chunks(query):\n",
    "    num_results = 3\n",
    "    results = query_milvus(query, num_results)\n",
    "\n",
    "    relevant_chunks = []\n",
    "    for i in range(num_results):    \n",
    "        #print(f\"id: {results[0].ids[i]}\")\n",
    "        #print(f\"distance: {results[0].distances[i]}\")\n",
    "        text = results[0][i].entity.get('article_text')\n",
    "        relevant_chunks.append(text)\n",
    "    \n",
    "    #print(relevant_chunks)\n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    context = \"\\n\\n\".join(context)\n",
    "    return (f\"{context}\\n\\nPlease answer a question using this text. \"\n",
    "          + f\"If the question is unanswerable, say \\\"unanswerable\\\".\"\n",
    "          + f\"\\n\\nQuestion: {question_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "# Model Parameters\n",
    "params = {\n",
    "        GenParams.DECODING_METHOD: \"greedy\",\n",
    "        GenParams.MIN_NEW_TOKENS: 1,\n",
    "        GenParams.MAX_NEW_TOKENS: 500,\n",
    "        GenParams.TEMPERATURE: 0,\n",
    "}\n",
    "model = Model(\n",
    "#        model_id='meta-llama/llama-2-70b-chat', \n",
    "        model_id='mistralai/mixtral-8x7b-instruct-v01',\n",
    "        params=params, credentials=creds, \n",
    "        project_id=project_id\n",
    ")\n",
    "\n",
    "# Prompt LLM\n",
    "def ask_llm(prompt):\n",
    "        response = model.generate_text(prompt)\n",
    "        #print(f\"Question: {question_text}{response}\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332637f55574431baa25502db389f587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(RadioButtons(description='Please choose', options=('without RAG', 'with RAG'), vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "text_input = widgets.Textarea(value=question_text, disabled=False)\n",
    "result_text = widgets.Textarea(value='', disabled=True)\n",
    "prompt_text = widgets.Textarea(value='', disabled=True)\n",
    "\n",
    "def on_click(b):\n",
    "#    display('You clicked the button!' + text_input.value + \" radio=\" + radio.value)\n",
    "    if (radio.value == \"without RAG\"):\n",
    "        result_text.value = \"asking AI (without RAG) ...\"\n",
    "        prompt = text_input.value\n",
    "    else:\n",
    "        result_text.value = \"asking AI (with RAG) ...\"\n",
    "        chunks = get_chunks(text_input.value)\n",
    "        prompt = make_prompt(chunks, text_input.value)\n",
    "    prompt_text.value = prompt\n",
    "    result_text.value = ask_llm(prompt)\n",
    "\n",
    "button = widgets.Button(description='Ask AI');\n",
    "button.on_click(on_click)\n",
    "\n",
    "radio=widgets.RadioButtons(options=['without RAG', 'with RAG'], description='Please choose')\n",
    "\n",
    "radio_box  = widgets.HBox([radio])\n",
    "input_box  = widgets.Box([widgets.Label('Your question!'), text_input, button])\n",
    "result_box = widgets.Box([result_text])\n",
    "prompt_box = widgets.Box([prompt_text])\n",
    "\n",
    "box = widgets.VBox(children=[radio_box, input_box , result_box, prompt_box])\n",
    "\n",
    "result_text.layout.width = '100%'\n",
    "result_text.layout.height = '200px'\n",
    "prompt_text.layout.width = '100%'\n",
    "\n",
    "display(box)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
