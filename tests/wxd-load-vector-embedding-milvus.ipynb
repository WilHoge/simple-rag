{"cells":[{"cell_type":"markdown","id":"b65a7e72","metadata":{},"source":["## Load Vector Embeddings to Milvus\n","\n","Here we will take the data we loaded into watsonx.data from the previous step and load it into the vector database Milvus. This data was previously chunked and stored in a watsonx.data hive table, so we'll pull from here, vectorize the text chunks and load them into Milvus.\n","\n","Before we can start loading the data, though, we need to create a collection in Milvus to hold the data. We'll call this collection `wiki_articles`. This collection holds the vector embeddings for each chunk of text, as well as the original text itself and additional context.\n","\n","Let's get started!"]},{"cell_type":"markdown","id":"b57832b9","metadata":{},"source":["#### Load credentials \n"]},{"cell_type":"code","execution_count":null,"id":"736fc30b-8ee7-4e34-8d53-cc652fed772d","metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","from ibm_cloud_sdk_core import IAMTokenManager\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","load_dotenv('config.env')\n","\n","# Connection variables\n","api_key = os.getenv(\"API_KEY\", None)\n","ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None) \n","project_id = os.getenv(\"PROJECT_ID\", None)\n","\n","creds = {\n","    \"url\": ibm_cloud_url,\n","    \"apikey\": api_key \n","}\n","access_token = IAMTokenManager(\n","    apikey = api_key,\n","    url = \"https://iam.cloud.ibm.com/identity/token\"\n",").get_token()"]},{"cell_type":"markdown","id":"d541d9f0","metadata":{},"source":["#### Create Lakehouse Connection\n","\n","We will use this watsonx.data connection to load the wikipedia articles."]},{"cell_type":"code","execution_count":null,"id":"ee9bcfb2","metadata":{},"outputs":[],"source":["import ssl\n","import urllib3\n","import os\n","from sqlalchemy import create_engine\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) # disable https warning\n","\n","LH_HOST_NAME=os.getenv(\"LH_HOST_NAME\", None)\n","LH_PORT=os.getenv(\"LH_PORT\", None) \n","LH_USER=os.getenv(\"LH_USER\", None)\n","LH_PW=os.getenv(\"LH_PW\", None)\n","LH_CATALOG='tpch'\n","LH_SCHEMA='tiny'\n","\n","try: \n","    quick_engine.dispose()\n","except:\n","    pass\n","\n","print(f\"presto://{LH_USER}:{LH_PW}@{LH_HOST_NAME}:{LH_PORT}/{LH_CATALOG}/{LH_SCHEMA}\")\n","\n","quick_engine = create_engine(\n","   f\"presto://{LH_USER}:{LH_PW}@{LH_HOST_NAME}:{LH_PORT}/{LH_CATALOG}/{LH_SCHEMA}\",\n","   connect_args={\n","    'protocol': 'https', \n","    'requests_kwargs': {'verify': ssl.CERT_NONE }\n","    }\n",")"]},{"cell_type":"markdown","id":"1ac807ed","metadata":{},"source":["#### Create Milvus Collection & Index\n","\n","Creating a Milvus collection involves first connecting to the Milvus server, then creating a collection with a defined schema and index. "]},{"cell_type":"code","execution_count":null,"id":"c9809752","metadata":{},"outputs":[],"source":["from pymilvus import(\n","    Milvus,\n","    IndexType,\n","    Status,\n","    connections,\n","    FieldSchema,\n","    DataType,\n","    Collection,\n","    CollectionSchema,\n",")\n","\n","import os \n","\n","host = os.getenv(\"MILVUS_HOST\", None)\n","port = os.getenv(\"MILVUS_PORT\", None)\n","password = os.getenv(\"LH_PW\", None)\n","user = os.getenv(\"LH_USER\", None)\n","server_pem_path = os.getenv(\"LH_CERT\", None)\n","\n","connections.connect(alias = 'default',\n","                   host = host,\n","                   port = port,\n","                   user = user,\n","                   password = password,\n","                   server_pem_path = server_pem_path,\n","                   server_name = host,\n","                   secure = True)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c9ec3092-707f-4654-b27c-e0e0485f3584","metadata":{},"outputs":[],"source":["# Create collection - define fields + schema\n","\n","fields = [\n","    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Primary key\n","    FieldSchema(name=\"article_text\", dtype=DataType.VARCHAR, max_length=2500,),\n","    FieldSchema(name=\"article_title\", dtype=DataType.VARCHAR, max_length=200,),\n","    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=384),\n","]\n","\n","schema = CollectionSchema(fields, \"wikipedia article collection schema\")\n","\n","wiki_collection = Collection(\"wiki_articles\", schema)\n","\n","# Create index\n","index_params = {\n","        'metric_type':'L2',\n","        'index_type':\"IVF_FLAT\",\n","        'params':{\"nlist\":2048}\n","}\n","\n","wiki_collection.create_index(field_name=\"vector\", index_params=index_params)"]},{"cell_type":"code","execution_count":null,"id":"7c718db4","metadata":{},"outputs":[],"source":["# Create collection - define fields + schema\n","\n","schema = CollectionSchema(fields, \"German wikipedia article collection schema\")\n","\n","wiki_collection_de = Collection(\"wiki_articles_de\", schema)\n","\n","# Create index\n","index_params = {\n","        'metric_type':'L2',\n","        'index_type':\"IVF_FLAT\",\n","        'params':{\"nlist\":2048}\n","}\n","\n","wiki_collection_de.create_index(field_name=\"vector\", index_params=index_params)"]},{"cell_type":"code","execution_count":null,"id":"f2c76e98-35dd-4dbe-816f-a397e8582aa7","metadata":{},"outputs":[],"source":["## Status(code=0, message=) means success! "]},{"cell_type":"code","execution_count":null,"id":"6247b193-7f82-4d94-a099-e6344e576319","metadata":{},"outputs":[],"source":["# we can run a check to see the collections in our milvus instance and we see 'wiki_articles'  has been created \n","\n","from pymilvus import utility\n","utility.list_collections()"]},{"cell_type":"markdown","id":"0f902a4e","metadata":{},"source":["#### Insert Vectors into Milvus\n","\n","Here we read data from the lakehouse table using the connection we created earlier. We pull text chunks and titles from the database, being sure to separate them out into separate lists. We then vectorize using the `sentence-transformers/all-MiniLM-L6-v2` sentence transformer model. Learn more about Hugging Face sentence transformers here: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n","\n","It is important we assemble the article text, article titles and vector embeddings into a `data` object. This object will be used to load the data into Milvus."]},{"cell_type":"code","execution_count":null,"id":"73aff6f1","metadata":{},"outputs":[],"source":["import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","from pymilvus import Collection, connections\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Download Wikipedia articles from watsonx.data using the engine we created earlier \n","\n","articles_df = pd.read_sql_query(\"select * from hive_data.watsonxai.wikipedia\",quick_engine)\n","\n","# extract text + titles\n","passages = articles_df['text'].tolist()\n","passage_titles = articles_df['title'].tolist()\n","\n","# Create vector embeddings + data\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n","passage_embeddings = model.encode(passages)\n","\n","basic_collection = Collection(\"wiki_articles\") \n","data = [\n","    passages,\n","    passage_titles,\n","    passage_embeddings\n","]\n","out = basic_collection.insert(data)\n","basic_collection.flush()  # Ensures data persistence"]},{"cell_type":"code","execution_count":null,"id":"860535eb","metadata":{},"outputs":[],"source":["import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","from pymilvus import Collection, connections\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Download Wikipedia articles from watsonx.data using the engine we created earlier \n","\n","articles_df = pd.read_sql_query(\"select * from hive_data.watsonxai.wikipedia_de\",quick_engine)\n","\n","# extract text + titles\n","passages = articles_df['text'].tolist()\n","passage_titles = articles_df['title'].tolist()\n","\n","# Create vector embeddings + data\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n","passage_embeddings = model.encode(passages)\n","\n","basic_collection = Collection(\"wiki_articles_de\") \n","data = [\n","    passages,\n","    passage_titles,\n","    passage_embeddings\n","]\n","out = basic_collection.insert(data)\n","basic_collection.flush()  # Ensures data persistence"]},{"cell_type":"code","execution_count":null,"id":"9692a46b-60e7-4636-9a87-7ffd397a599e","metadata":{},"outputs":[],"source":["## check to ensure entities have been loaded into 'wiki_articles' collection\n","\n","basic_collection = Collection(\"wiki_articles\") \n","\n","basic_collection.num_entities "]},{"cell_type":"code","execution_count":null,"id":"0ee910f9","metadata":{},"outputs":[],"source":["## check to ensure entities have been loaded into 'wiki_articles' collection\n","\n","basic_collection = Collection(\"wiki_articles_de\") \n","\n","basic_collection.num_entities "]},{"cell_type":"code","execution_count":null,"id":"f4cd4df5","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
