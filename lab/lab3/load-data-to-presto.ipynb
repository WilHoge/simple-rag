{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data to Presto in watsonx.data\n",
    "\n",
    "In order to provide context automatically, this information has to be stored in a local database. Therefore, in this lab we collect data from the internet and store it in watsonx.data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "import wxd_utils\n",
    "\n",
    "conf=wxd_utils.load_conf()\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from wikipedia\n",
    "\n",
    "We get data from wikipedia about the nobel price winner in literature in 2023. This data is used as context for our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# fetch wikipedia articles\n",
    "articles = {\n",
    "    'Nobel price in literature': None, \n",
    "    '2023 Nobel price in literature': 72508137,\n",
    "    '2024 Nobel price in literature': 75098159\n",
    "}\n",
    "for k,v in articles.items():\n",
    "    if v:\n",
    "        article = wikipedia.page(pageid=v)\n",
    "    else:\n",
    "        article = wikipedia.page(k)\n",
    "    articles[k] = article.content\n",
    "    print(f\"Successfully fetched {k}\")\n",
    "\n",
    "print(f\"Successfully fetched {len(articles)} articles \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect watsonx.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wxd_engine = wxd_utils.connect_wxd(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Schema in watsonx.data bucket on object storage to store wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "try: \n",
    "  create_schema_result = pd.read_sql(\"\"\"\n",
    "\n",
    "    CREATE SCHEMA IF NOT EXISTS iceberg_data.simple_rag WITH ( location = 's3a://iceberg-bucket/simple_rag')\n",
    "\n",
    "    \"\"\", wxd_engine)\n",
    "  \n",
    "except sqlalchemy.exc.SQLAlchemyError as e:\n",
    "  print(\"Error creating schema:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table to hold wikipedia data in schema from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    create_table_result = pd.read_sql(\"\"\"\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS iceberg_data.simple_rag.wikipedia\n",
    "        (\n",
    "            \"id\" varchar,\n",
    "            \"text\" varchar, \n",
    "            \"title\" varchar  )\n",
    "        WITH (\n",
    "            format = 'PARQUET'\n",
    "        )\n",
    "     \n",
    "    \"\"\", wxd_engine)\n",
    "  \n",
    "except sqlalchemy.exc.SQLAlchemyError as e:\n",
    "  print(\"Error creating table:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk and insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = wxd_utils.chunk_articles(articles, 255)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for item in chunks:\n",
    "    insert_stmt = f\"insert into iceberg_data.simple_rag.wikipedia values ('{item['id']}', '{item['chunk']}', '{item['title']}')\"\n",
    "            \n",
    "    with wxd_engine.connect() as connection:\n",
    "        connection.execute(insert_stmt)\n",
    "    \n",
    "    print(f\"{item['title']} {i}/{len(chunks)} INSERTED\")\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm data inserted\n",
    "\n",
    "wiki_articles = pd.read_sql(\"select * from iceberg_data.simple_rag.wikipedia\", wxd_engine)\n",
    "wiki_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed cleanup your dataset (change condition to do so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    try:\n",
    "\n",
    "        drop_table = \"drop table iceberg_data.simple_rag.wikipedia\"\n",
    "        drop_schema = \"drop schema iceberg_data.simple_rag\"\n",
    "\n",
    "        with wxd_engine.connect() as connection:\n",
    "                connection.execute(drop_table)\n",
    "                connection.execute(drop_schema)\n",
    "\n",
    "    except sqlalchemy.exc.SQLAlchemyError as e:\n",
    "        print(\"Error:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
